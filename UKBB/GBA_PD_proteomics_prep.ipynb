{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing proteomics data - GBA-PD vs. GBA-Ctrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Use cohort browser to find Participant IDs for people that have proteomics data\n",
    "According to data manifest and UKBB docs (https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=30900 ; https://dnanexus.gitbook.io/uk-biobank-rap/getting-started/data-structure):\n",
    "- Add filter → Biological samples → Blood assays → Proteomics → Protein biomarkers → Number of proteins measured | Instance 0, Add cohort filter IS NOT NULL\n",
    "\n",
    "52,995 subjects subjects have proteomics data (NOT null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Count number of GBA-PD subjects with proteomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing PD subjects\n",
    "# (Health related outcomes -> First occurrences -> Nervous system disorders -> Source of report of G20 (parkinson's disease) | all except \"Self-report only\" and missing values)\n",
    "import pandas as pd\n",
    "\n",
    "PD_patients = pd.read_csv(\"/mnt/project/UKBB_participant_IDs_w_PD.csv\")\n",
    "PD_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing proteomics subjects\n",
    "proteo_subjects = pd.read_csv(\"./UKBB_participant_IDs_w_proteomics.csv\")\n",
    "proteo_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download plink2\n",
    "!wget https://s3.amazonaws.com/plink2-assets/plink2_linux_x86_64_latest.zip\n",
    "!unzip plink2_linux_x86_64_latest.zip\n",
    "!chmod +x plink2\n",
    "\n",
    "!dx upload plink2 --destination ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining a function to extract information (by Jeff Kim)\n",
    "def extract_alternate_carriers_vectorized(raw_file, include_count=False):\n",
    "    \"\"\"\n",
    "    Process PLINK2 raw format (--recode A) to extract participants carrying alternate alleles\n",
    "    using vectorized operations for improved performance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw_file : str\n",
    "        Path to the PLINK2 raw format file\n",
    "    include_count : bool, default=False\n",
    "        If True, output will include a COUNT column with allele counts\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns:\n",
    "        - IID: Sample identifier\n",
    "        - VARID: Comma-separated list of variants with alternate alleles\n",
    "        - COUNT: (Only if include_count=True) Comma-separated list of allele counts\n",
    "                 corresponding to each variant in VARID\n",
    "                 0 = Homozygous alternate, 1 = Heterozygous\n",
    "    \"\"\"\n",
    "    # Read the raw file\n",
    "    df = pd.read_csv(raw_file, sep = r'\\s+')\n",
    "    \n",
    "    # Get the variant IDs (column names after the first 6 columns)\n",
    "    variant_cols = df.columns[6:]\n",
    "    \n",
    "    # Pre-clean variant names (remove _REF part) - only do this operation once\n",
    "    clean_variants = np.array([var.split('_')[0] for var in variant_cols])\n",
    "    \n",
    "    # Extract genotype data as numpy array for faster processing\n",
    "    genotype_array = df[variant_cols].values\n",
    "    \n",
    "    # Get IIDs as numpy array\n",
    "    iids = df['IID'].values\n",
    "    \n",
    "    # Initialize result dictionaries\n",
    "    result_dict = {}\n",
    "    count_dict = {}\n",
    "    \n",
    "    # Identify alternate allele carriers (value < 2)\n",
    "    alt_allele_mask = genotype_array < 2\n",
    "    \n",
    "    # Process each sample\n",
    "    for i in range(len(df)):\n",
    "        # Find variants where this sample has alternate alleles\n",
    "        alt_indices = np.where(alt_allele_mask[i])[0]\n",
    "        \n",
    "        # Only include samples with at least one alternate allele\n",
    "        if len(alt_indices) > 0:\n",
    "            # Get the variant IDs\n",
    "            alternate_variants = clean_variants[alt_indices]\n",
    "            \n",
    "            # Join variant IDs\n",
    "            result_dict[iids[i]] = ','.join(alternate_variants)\n",
    "            \n",
    "            if include_count:\n",
    "                # Get the actual count values (0 or 1) for these variants\n",
    "                count_values = genotype_array[i, alt_indices]\n",
    "                # Convert to strings and join\n",
    "                count_dict[iids[i]] = ','.join(map(str, count_values))\n",
    "    \n",
    "    # Convert the dictionaries to a DataFrame\n",
    "    if include_count:\n",
    "        result_df = pd.DataFrame({\n",
    "            'IID': list(result_dict.keys()),\n",
    "            'VARID': list(result_dict.values()),\n",
    "            'COUNT': [count_dict[iid] for iid in result_dict.keys()]\n",
    "        })\n",
    "    else:\n",
    "        result_df = pd.DataFrame(list(result_dict.items()), \n",
    "                               columns=['IID', 'VARID'])\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing GBA carrier information (.raw file generated in \"extracting_GBA_carriers_ok.ipynb\")\n",
    "import numpy as np\n",
    "\n",
    "GBA1_carriers = extract_alternate_carriers_vectorized(\"/mnt/project/GBA1_risk_variants_raw.raw\", include_count=True)\n",
    "GBA1_E326K_carriers = GBA1_carriers[GBA1_carriers['VARID'].str.contains('1:155236376:C:T')]\n",
    "GBA1_noE326K_carriers = GBA1_carriers[GBA1_carriers['VARID'] != ('1:155236376:C:T')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find GBA-PD cases through ID overlaps\n",
    "GBA1_PD_carriers = GBA1_carriers[GBA1_carriers['IID'].isin(PD_patients['Participant ID'])]\n",
    "GBA1_PD_carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_PD_E326K_carriers = GBA1_E326K_carriers[GBA1_E326K_carriers['IID'].isin(PD_patients['Participant ID'])]\n",
    "GBA1_PD_E326K_carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_PD_noE326K_carriers = GBA1_noE326K_carriers[GBA1_noE326K_carriers['IID'].isin(PD_patients['Participant ID'])]\n",
    "GBA1_PD_noE326K_carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find GBA-PD carriers with proteomics\n",
    "GBA1_PD_proteo = GBA1_PD_carriers[GBA1_PD_carriers['IID'].isin(proteo_subjects['column'])]\n",
    "GBA1_PD_proteo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Count number of GBA-Ctrl subjects with proteomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, use cohort browser to get trustworthy list of \"no PD\" subjects\n",
    "# (Health related outcomes -> First occurrences -> Nervous system disorders -> Source of report of G20 (parkinson's disease) | none with PD or missing values;\n",
    "# No family history)\n",
    "\n",
    "# Jeff already created participant lists of family history and they're inside \"participant_list\"\n",
    "PD_parent_history = pd.read_csv(\"/mnt/project/participant_list/UKB_has_PD_parent.csv\")\n",
    "PD_parent_history.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PD_sibling_history = pd.read_csv(\"/mnt/project/participant_list/UKB_has_PD_sibling.csv\")\n",
    "PD_sibling_history.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PD_history = PD_parent_history['column'] + PD_sibling_history['column']\n",
    "PD_history.shape[0] # is a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_carriers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_Ctrl_carriers = GBA1_carriers[~GBA1_carriers['IID'].isin(PD_patients['Participant ID'])]\n",
    "GBA1_Ctrl_carriers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NoPD_subjects = pd.read_csv(\"./UKBB_participant_IDs_without_PD.csv\")\n",
    "NoPD_subjects.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NoPD_NoHistory = NoPD_subjects[~NoPD_subjects['column'].isin(PD_history)]\n",
    "NoPD_NoHistory.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally counting GBA-Ctrl and GBA-Ctrl with proteomics\n",
    "GBA1_Ctrl_carriers = GBA1_carriers[GBA1_carriers['IID'].isin(NoPD_NoHistory['column'])]\n",
    "GBA1_Ctrl_carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_Ctrl_E326K_carriers = GBA1_E326K_carriers[GBA1_E326K_carriers['IID'].isin(NoPD_NoHistory['column'])]\n",
    "GBA1_Ctrl_E326K_carriers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_Ctrl_noE326K_carriers = GBA1_noE326K_carriers[GBA1_noE326K_carriers['IID'].isin(NoPD_NoHistory['column'])]\n",
    "GBA1_Ctrl_noE326K_carriers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_Ctrl_proteo = GBA1_Ctrl_carriers[GBA1_Ctrl_carriers['IID'].isin(proteo_subjects['column'])]\n",
    "GBA1_Ctrl_proteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save all relevant files into permanent storage\n",
    "GBA1_PD_proteo.to_csv(\"GBA1_PD_proteo.txt\", sep=\"\\t\", index=False)\n",
    "GBA1_Ctrl_proteo.to_csv(\"GBA1_Ctrl_proteo.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "!dx upload UKBB_participant* --destination ./\n",
    "!dx upload GBA1_* --destination ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Find and extract proteomics data\n",
    "Useful GitHub repositories: https://github.com/dnanexus/UKB_RAP/blob/main/proteomics/ ; https://github.com/UK-Biobank/UKB-RAP-Notebooks-Access/blob/main/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!dx ls Bulk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# dxpy allows python to interact with the platform storage\n",
    "import dxpy\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"/proteomics_results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically discover dispensed dataset ID\n",
    "dispensed_dataset = dxpy.find_one_data_object(\n",
    "    typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\"\n",
    ")\n",
    "dispensed_dataset_id = dispensed_dataset[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dispensed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get project ID\n",
    "project_id = dxpy.find_one_project()[\"id\"]\n",
    "project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = (\":\").join([project_id, dispensed_dataset_id])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: This cell can only be run once. Otherwise, you'll need to delete the existing data tables in order to re-run\n",
    "cmd = [\"dx\", \"extract_dataset\", dataset, \"-ddd\", \"--delimiter\", \",\"]\n",
    "subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get field names\n",
    "path = os.getcwd()\n",
    "\n",
    "data_dict_csv = glob.glob(os.path.join(path, \"*.data_dictionary.csv\"))[0]\n",
    "data_dict_df = pd.read_csv(data_dict_csv)\n",
    "data_dict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "field_names = list(\n",
    "    data_dict_df.loc[data_dict_df[\"entity\"] == \"olink_instance_0\", \"name\"].values\n",
    ")\n",
    "print(len(field_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "field_names[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look for CTS proteins\n",
    "matches = [item for item in field_names if \"cts\".lower() in item.lower()]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Extract abundance data itself\n",
    "# For that, you need to open a Spark instance (basically, open a new JupyterLab instance and select a Spark cluster).\n",
    "\n",
    "# An automatic Jupyter notebook will be created (Spark_notebook.py), which will already have some sample code to help you with the extraction, but you can also use code from the following notebooks:\n",
    "# https://github.com/UK-Biobank/UKB-RAP-Notebooks-Access/blob/main/JupyterNotebook_R/A108_Constructing-the-Olink-dataset_R.ipynb\n",
    "# https://github.com/dnanexus/UKB_RAP/blob/main/proteomics/0_extract_phenotype_protein_data.ipynb\n",
    "\n",
    "# After extracting the data, don't forget to save into your workspace and load it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Basic preprocessing steps\n",
    "1. (pre-processing) Filter samples based on metadata\n",
    "2. (exploration) Examine the distribution of expression per protein\n",
    "3. (exploration) PCA visualization of the data to determine if there are any outliers\n",
    "4. (pre-processing) (if needed) Normalization\n",
    "\n",
    "Sample notebook: https://github.com/dnanexus/UKB_RAP/blob/main/proteomics/protein_DE_analysis/1_preprocess_explore_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rescuing patient information\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "GBA1_PD_proteo = pd.read_csv(\"/mnt/project/GBA1_PD_proteo.txt\", sep=\"\\t\")\n",
    "GBA1_Ctrl_proteo = pd.read_csv(\"/mnt/project/GBA1_Ctrl_proteo.txt\", sep=\"\\t\")\n",
    "\n",
    "GBA1_PD_proteo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rescuing protein abundances\n",
    "proteomics = pd.read_csv(\"complete_proteomics_df.txt\", sep=\"\\t\") # also in DNAnexus:proteomics_results\n",
    "proteomics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look for CTS proteins\n",
    "proteomics.columns = proteomics.columns.str.replace(\"olink_instance_0.\", \"\", case=False)\n",
    "\n",
    "matches2 = [col for col in proteomics.columns if col.lower().startswith(\"cts\")]\n",
    "matches2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_PD_abund = proteomics[proteomics['eid'].isin(GBA1_PD_proteo['IID'])]\n",
    "GBA1_Ctrl_abund = proteomics[proteomics['eid'].isin(GBA1_Ctrl_proteo['IID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(GBA1_PD_abund)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(GBA1_Ctrl_abund)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_PD_abund_cts = GBA1_PD_abund[ [\"eid\"] + matches2 ]\n",
    "GBA1_PD_abund_cts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_Ctrl_abund_cts = GBA1_Ctrl_abund[ [\"eid\"] + matches2 ]\n",
    "GBA1_Ctrl_abund_cts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check data distribution\n",
    "GBA1_PD_abund_cts[\"ctsb\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBA1_Ctrl_abund_cts[\"ctsb\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCA plot\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = GBA1_PD_abund_cts.iloc[:, 1:].dropna()\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_df)\n",
    "\n",
    "pca = PCA(n_components=2)  # 2 components for 2D plot\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Convert to a dataframe for plotting\n",
    "pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(pca_df['PC1'], pca_df['PC2'])\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)\")\n",
    "plt.title(\"PCA Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = GBA1_Ctrl_abund_cts.iloc[:, 1:].dropna()\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_df)\n",
    "\n",
    "pca = PCA(n_components=2)  # 2 components for 2D plot\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Convert to a dataframe for plotting\n",
    "pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(pca_df['PC1'], pca_df['PC2'])\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)\")\n",
    "plt.title(\"PCA Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Basic \"differential expression\" analysis\n",
    "Since our goal is just to have a quick look at the protein expression of cathepsins between GBA-PD and GBA-Ctrl subjects, we will run simple t-tests not adjusted for multiple comparisons nor adjusted for covariates.\n",
    "We also did not impute the data, so we only used non-NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "# Example dataframes\n",
    "# cases_df and controls_df have the same columns: first column is 'subject_id', others are proteins\n",
    "# Drop subject ID for analysis\n",
    "case_proteins = GBA1_PD_abund_cts.iloc[:, 1:]\n",
    "control_proteins = GBA1_Ctrl_abund_cts.iloc[:, 1:]\n",
    "\n",
    "# Prepare output dataframe\n",
    "results = pd.DataFrame(columns=[\"protein\", \"mean_case\", \"mean_control\", \"log2FC\", \"p_value\"])\n",
    "\n",
    "# Loop through each protein\n",
    "for protein in case_proteins.columns:\n",
    "    case_values = case_proteins[protein].dropna()\n",
    "    control_values = control_proteins[protein].dropna()\n",
    "    \n",
    "    # t-test\n",
    "    t_stat, p_val = ttest_ind(case_values, control_values, equal_var=False)\n",
    "    \n",
    "    # Means\n",
    "    mean_case = case_values.mean()\n",
    "    mean_control = control_values.mean()\n",
    "    \n",
    "    # log2 fold change\n",
    "    # Add small pseudocount if any mean is zero to avoid division by zero\n",
    "    #log2fc = np.log2((mean_case + 1e-9) / (mean_control + 1e-9))\n",
    "    log2fc = mean_case - mean_control # data seems to be already log2 transformed\n",
    "    \n",
    "    # Append to results\n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        \"protein\": [protein],\n",
    "        \"mean_case\": [mean_case],\n",
    "        \"mean_control\": [mean_control],\n",
    "        \"log2FC\": [log2fc],\n",
    "        \"p_value\": [p_val]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "# Optional: sort by p-value\n",
    "results = results.sort_values(\"p_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot boxplots of selected proteins\n",
    "selected_proteins = [\"ctsv\", \"ctsz\"]\n",
    "\n",
    "# Melt dataframes to long format\n",
    "cases_long = GBA1_PD_abund_cts\n",
    "controls_long = GBA1_Ctrl_abund_cts\n",
    "\n",
    "cases_long = cases_long.melt(id_vars=\"eid\", value_vars=selected_proteins, \n",
    "                            var_name=\"protein\", value_name=\"abundance\")\n",
    "cases_long[\"group\"] = \"case\"\n",
    "\n",
    "controls_long = controls_long.melt(id_vars=\"eid\", value_vars=selected_proteins, \n",
    "                                 var_name=\"protein\", value_name=\"abundance\")\n",
    "controls_long[\"group\"] = \"control\"\n",
    "\n",
    "# Combine\n",
    "plot_df = pd.concat([cases_long, controls_long], ignore_index=True)\n",
    "\n",
    "# Replace inf/-inf with NaN\n",
    "plot_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with NaN\n",
    "plot_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6,10))\n",
    "sns.boxplot(x=\"protein\", y=\"abundance\", hue=\"group\", data=plot_df, palette=\"Set2\",\n",
    "            hue_order=[\"control\", \"case\"])\n",
    "sns.stripplot(x=\"protein\", y=\"abundance\", hue=\"group\", data=plot_df, \n",
    "              color=\"black\", alpha=0.5, dodge=True, jitter=True,\n",
    "              hue_order=[\"control\", \"case\"])\n",
    "\n",
    "plt.title(\"Protein abundance: Case vs Control\")\n",
    "plt.ylabel(\"Abundance\")\n",
    "plt.xlabel(\"Protein\")\n",
    "plt.legend(title=\"Group\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload final files\n",
    "results.to_csv(\"t-test_CTS_proteins_GBA-PD_vs_GBA-Ctrl.txt\", sep=\"\\t\", index=False)\n",
    "!dx upload t-test_CTS_proteins_GBA-PD_vs_GBA-Ctrl.txt --destination proteomics_results/\n",
    "\n",
    "plt.savefig(\"CTS_boxplots_GBA-PD_vs_GBA-Ctrl.pdf\", format=\"pdf\", bbox_inches=\"tight\")  # tight trims extra whitespace\n",
    "!dx upload CTS_boxplots_GBA-PD_vs_GBA-Ctrl.pdf --destination proteomics_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
